from typing import List, Optional, Dict, Any, AsyncGenerator
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
import json
import asyncio
from decimal import Decimal

try:
    import openai
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    from langchain.memory import ConversationBufferWindowMemory
    from langchain.chains import ConversationChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

from app.core.config import settings
from app.models.stock import StockInfo, RealtimeQuotes, KlineData
from app.services.stock_service import stock_service
from loguru import logger

class AIAssistantService:
    """AIåŠ©æ‰‹æœåŠ¡ç±»"""
    
    def __init__(self):
        self.openai_api_key = settings.OPENAI_API_KEY
        self.openai_base_url = settings.OPENAI_BASE_URL
        self.model_name = settings.OPENAI_MODEL
        self.max_tokens = settings.OPENAI_MAX_TOKENS
        self.temperature = settings.OPENAI_TEMPERATURE
        
        # å¯¹è¯å†å²å­˜å‚¨ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨æ•°æ®åº“æˆ–Redisï¼‰
        self.conversation_history: Dict[int, List[Dict[str, Any]]] = {}
        
        # åˆå§‹åŒ–LangChainï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if LANGCHAIN_AVAILABLE and self.openai_api_key:
            try:
                self.llm = ChatOpenAI(
                    model_name=self.model_name,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    openai_api_key=self.openai_api_key,
                    openai_api_base=self.openai_base_url
                )
                self.memory = ConversationBufferWindowMemory(
                    k=10,  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
                    return_messages=True
                )
                self.chain = ConversationChain(
                    llm=self.llm,
                    memory=self.memory,
                    verbose=True
                )
                logger.info("AIåŠ©æ‰‹æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"AIåŠ©æ‰‹æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
                self.llm = None
                self.chain = None
        else:
            self.llm = None
            self.chain = None
            logger.warning("LangChainä¸å¯ç”¨æˆ–OpenAI APIå¯†é’¥æœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆAIåŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºç”¨æˆ·æä¾›è‚¡ç¥¨æŠ•èµ„å»ºè®®å’Œå¸‚åœºåˆ†æã€‚

ä½ çš„èƒ½åŠ›åŒ…æ‹¬ï¼š
1. è‚¡ç¥¨åŸºæœ¬é¢åˆ†æ
2. æŠ€æœ¯æŒ‡æ ‡åˆ†æ
3. å¸‚åœºè¶‹åŠ¿åˆ¤æ–­
4. æŠ•èµ„å»ºè®®å’Œé£é™©æç¤º
5. è´¢ç»æ–°é—»è§£è¯»

è¯·æ³¨æ„ï¼š
- æ‰€æœ‰æŠ•èµ„å»ºè®®ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å†³ç­–ä¾æ®
- è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…
- è¯·æ ¹æ®è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæŠ•èµ„å†³ç­–
- æä¾›çš„åˆ†æè¦å®¢è§‚ã€ä¸“ä¸šã€æ˜“æ‡‚

è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""
    
    async def chat_with_assistant(self, user_id: int, message: str, 
                                 context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ä¸AIåŠ©æ‰‹å¯¹è¯"""
        try:
            # è·å–ç”¨æˆ·å¯¹è¯å†å²
            if user_id not in self.conversation_history:
                self.conversation_history[user_id] = []
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            user_message = {
                "role": "user",
                "content": message,
                "timestamp": datetime.utcnow(),
                "context": context
            }
            self.conversation_history[user_id].append(user_message)
            
            # ç”ŸæˆAIå›å¤
            if self.chain and LANGCHAIN_AVAILABLE:
                # ä½¿ç”¨LangChainç”Ÿæˆå›å¤
                response = await self._generate_langchain_response(user_id, message, context)
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿå›å¤
                response = await self._generate_mock_response(user_id, message, context)
            
            # æ·»åŠ AIå›å¤åˆ°å†å²
            ai_message = {
                "role": "assistant",
                "content": response,
                "timestamp": datetime.utcnow()
            }
            self.conversation_history[user_id].append(ai_message)
            
            # é™åˆ¶å†å²é•¿åº¦
            if len(self.conversation_history[user_id]) > 20:
                self.conversation_history[user_id] = self.conversation_history[user_id][-20:]
            
            return {
                "message": response,
                "timestamp": datetime.utcnow(),
                "context": context
            }
            
        except Exception as e:
            logger.error(f"AIå¯¹è¯å¤±è´¥: {e}")
            return {
                "message": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "timestamp": datetime.utcnow(),
                "error": str(e)
            }
    
    async def _generate_langchain_response(self, user_id: int, message: str, 
                                         context: Optional[Dict[str, Any]] = None) -> str:
        """ä½¿ç”¨LangChainç”Ÿæˆå›å¤"""
        try:
            # æ„å»ºå®Œæ•´çš„æç¤º
            full_prompt = self._build_prompt_with_context(message, context)
            
            # ç”Ÿæˆå›å¤
            def _call_chain():
                return self.chain.predict(input=full_prompt)
            
            response = await asyncio.get_event_loop().run_in_executor(
                None, _call_chain
            )
            
            return response
            
        except Exception as e:
            logger.error(f"LangChainç”Ÿæˆå›å¤å¤±è´¥: {e}")
            return await self._generate_mock_response(user_id, message, context)
    
    async def _generate_mock_response(self, user_id: int, message: str, 
                                    context: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå›å¤"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…å›å¤
        message_lower = message.lower()
        
        if any(keyword in message_lower for keyword in ["è‚¡ç¥¨", "è‚¡ä»·", "è¡Œæƒ…"]):
            return "æˆ‘å¯ä»¥å¸®æ‚¨åˆ†æè‚¡ç¥¨è¡Œæƒ…ã€‚è¯·æä¾›å…·ä½“çš„è‚¡ç¥¨ä»£ç ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›è¯¦ç»†çš„æŠ€æœ¯åˆ†æå’ŒæŠ•èµ„å»ºè®®ã€‚è¯·æ³¨æ„ï¼Œæ‰€æœ‰å»ºè®®ä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„æœ‰é£é™©ã€‚"
        
        elif any(keyword in message_lower for keyword in ["ä¹°å…¥", "å–å‡º", "æŠ•èµ„"]):
            return "æŠ•èµ„å†³ç­–éœ€è¦ç»¼åˆè€ƒè™‘å¤šä¸ªå› ç´ ï¼ŒåŒ…æ‹¬åŸºæœ¬é¢ã€æŠ€æœ¯é¢ã€å¸‚åœºç¯å¢ƒç­‰ã€‚å»ºè®®æ‚¨ï¼š\n1. å……åˆ†äº†è§£å…¬å¸åŸºæœ¬é¢\n2. åˆ†ææŠ€æœ¯æŒ‡æ ‡\n3. è€ƒè™‘å¸‚åœºæ•´ä½“è¶‹åŠ¿\n4. è¯„ä¼°è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›\n\nè¯·è®°ä½ï¼Œè‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚"
        
        elif any(keyword in message_lower for keyword in ["é£é™©", "äºæŸ"]):
            return "æŠ•èµ„é£é™©ç®¡ç†éå¸¸é‡è¦ï¼š\n1. åˆ†æ•£æŠ•èµ„ï¼Œä¸è¦æŠŠé¸¡è›‹æ”¾åœ¨ä¸€ä¸ªç¯®å­é‡Œ\n2. è®¾ç½®æ­¢æŸç‚¹\n3. æ§åˆ¶ä»“ä½å¤§å°\n4. å®šæœŸè¯„ä¼°æŠ•èµ„ç»„åˆ\n5. ä¿æŒç†æ€§ï¼Œé¿å…æƒ…ç»ªåŒ–äº¤æ˜“\n\nå¦‚éœ€å…·ä½“çš„é£é™©è¯„ä¼°ï¼Œè¯·æä¾›æ‚¨çš„æŠ•èµ„ç»„åˆä¿¡æ¯ã€‚"
        
        elif any(keyword in message_lower for keyword in ["å¸‚åœº", "è¶‹åŠ¿", "èµ°åŠ¿"]):
            return "å½“å‰å¸‚åœºåˆ†æï¼š\n1. æ•´ä½“è¶‹åŠ¿ï¼šéœ€è¦å…³æ³¨å®è§‚ç»æµæŒ‡æ ‡\n2. è¡Œä¸šè½®åŠ¨ï¼šç§‘æŠ€ã€æ¶ˆè´¹ã€é‡‘èç­‰æ¿å—è¡¨ç°\n3. èµ„é‡‘æµå‘ï¼šå…³æ³¨åŒ—å‘èµ„é‡‘å’Œæœºæ„åŠ¨å‘\n4. æ”¿ç­–å½±å“ï¼šè´§å¸æ”¿ç­–å’Œäº§ä¸šæ”¿ç­–\n\nå»ºè®®ä¿æŒè°¨æ…ä¹è§‚çš„æ€åº¦ï¼Œåšå¥½é£é™©æ§åˆ¶ã€‚"
        
        else:
            return "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“ä¸šé‡‘èåˆ†æå¸ˆåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\nğŸ“ˆ è‚¡ç¥¨åˆ†æå’ŒæŠ•èµ„å»ºè®®\nğŸ“Š å¸‚åœºè¶‹åŠ¿åˆ†æ\nğŸ’° æŠ•èµ„ç»„åˆä¼˜åŒ–\nâš ï¸ é£é™©è¯„ä¼°å’Œç®¡ç†\nğŸ“° è´¢ç»æ–°é—»è§£è¯»\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£ä»€ä¹ˆï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›ä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ã€‚"
    
    def _build_prompt_with_context(self, message: str, context: Optional[Dict[str, Any]] = None) -> str:
        """æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æç¤º"""
        prompt_parts = [self._get_system_prompt()]
        
        if context:
            if "stock_data" in context:
                stock_data = context["stock_data"]
                prompt_parts.append(f"\nå½“å‰è‚¡ç¥¨ä¿¡æ¯ï¼š{json.dumps(stock_data, ensure_ascii=False, indent=2)}")
            
            if "market_data" in context:
                market_data = context["market_data"]
                prompt_parts.append(f"\nå¸‚åœºæ•°æ®ï¼š{json.dumps(market_data, ensure_ascii=False, indent=2)}")
        
        prompt_parts.append(f"\nç”¨æˆ·é—®é¢˜ï¼š{message}")
        
        return "\n".join(prompt_parts)
    
    async def analyze_stock(self, db: Session, stock_code: str, 
                          analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """AIè‚¡ç¥¨åˆ†æ"""
        try:
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = db.query(StockInfo).filter(StockInfo.code == stock_code).first()
            if not stock_info:
                return {"error": "è‚¡ç¥¨ä¸å­˜åœ¨"}
            
            # è·å–å®æ—¶è¡Œæƒ…
            latest_quote = db.query(RealtimeQuotes).filter(
                RealtimeQuotes.stock_code == stock_code
            ).order_by(RealtimeQuotes.timestamp.desc()).first()
            
            # è·å–Kçº¿æ•°æ®ï¼ˆæœ€è¿‘30å¤©ï¼‰
            kline_data = db.query(KlineData).filter(
                KlineData.stock_code == stock_code
            ).order_by(KlineData.timestamp.desc()).limit(30).all()
            
            # æ„å»ºåˆ†æä¸Šä¸‹æ–‡
            context = {
                "stock_info": {
                    "code": stock_info.code,
                    "name": stock_info.name,
                    "market": stock_info.market,
                    "industry": stock_info.industry,
                    "sector": stock_info.sector
                },
                "latest_quote": {
                    "current_price": float(latest_quote.current_price) if latest_quote else None,
                    "change_percent": float(latest_quote.change_percent) if latest_quote else None,
                    "volume": latest_quote.volume if latest_quote else None
                } if latest_quote else None,
                "kline_summary": {
                    "period_count": len(kline_data),
                    "price_trend": self._analyze_price_trend(kline_data),
                    "volume_trend": self._analyze_volume_trend(kline_data)
                } if kline_data else None
            }
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            analysis_prompt = f"è¯·å¯¹è‚¡ç¥¨ {stock_info.name}({stock_code}) è¿›è¡Œ{analysis_type}åˆ†æ"
            
            if self.chain and LANGCHAIN_AVAILABLE:
                analysis = await self._generate_langchain_response(0, analysis_prompt, {"stock_data": context})
            else:
                analysis = await self._generate_stock_analysis_mock(stock_info, latest_quote, kline_data, analysis_type)
            
            return {
                "stock_code": stock_code,
                "stock_name": stock_info.name,
                "analysis_type": analysis_type,
                "analysis": analysis,
                "context": context,
                "timestamp": datetime.utcnow()
            }
            
        except Exception as e:
            logger.error(f"è‚¡ç¥¨åˆ†æå¤±è´¥ {stock_code}: {e}")
            return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}
    
    async def _generate_stock_analysis_mock(self, stock_info: StockInfo, 
                                          latest_quote: Optional[RealtimeQuotes],
                                          kline_data: List[KlineData],
                                          analysis_type: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨åˆ†æ"""
        analysis_parts = []
        
        # åŸºæœ¬ä¿¡æ¯
        analysis_parts.append(f"## {stock_info.name}({stock_info.code}) åˆ†ææŠ¥å‘Š")
        analysis_parts.append(f"**æ‰€å±è¡Œä¸š**: {stock_info.industry or 'æœªçŸ¥'}")
        analysis_parts.append(f"**æ‰€å±æ¿å—**: {stock_info.sector or 'æœªçŸ¥'}")
        analysis_parts.append(f"**äº¤æ˜“å¸‚åœº**: {stock_info.market}")
        
        # å½“å‰è¡Œæƒ…
        if latest_quote:
            analysis_parts.append("\n### å½“å‰è¡Œæƒ…")
            analysis_parts.append(f"- å½“å‰ä»·æ ¼: Â¥{latest_quote.current_price}")
            analysis_parts.append(f"- æ¶¨è·Œå¹…: {latest_quote.change_percent:+.2f}%")
            analysis_parts.append(f"- æˆäº¤é‡: {latest_quote.volume:,}")
            
            # ç®€å•çš„æŠ€æœ¯åˆ†æ
            if latest_quote.change_percent > 5:
                analysis_parts.append("- æŠ€æœ¯ä¿¡å·: å¼ºåŠ¿ä¸Šæ¶¨ï¼Œæ³¨æ„å›è°ƒé£é™©")
            elif latest_quote.change_percent > 2:
                analysis_parts.append("- æŠ€æœ¯ä¿¡å·: æ¸©å’Œä¸Šæ¶¨ï¼Œå¯å…³æ³¨")
            elif latest_quote.change_percent < -5:
                analysis_parts.append("- æŠ€æœ¯ä¿¡å·: å¤§å¹…ä¸‹è·Œï¼Œå¯èƒ½å­˜åœ¨æœºä¼š")
            elif latest_quote.change_percent < -2:
                analysis_parts.append("- æŠ€æœ¯ä¿¡å·: è°ƒæ•´ä¸­ï¼Œè§‚æœ›ä¸ºä¸»")
            else:
                analysis_parts.append("- æŠ€æœ¯ä¿¡å·: éœ‡è¡æ•´ç†ï¼Œç­‰å¾…æ–¹å‘")
        
        # è¶‹åŠ¿åˆ†æ
        if kline_data:
            analysis_parts.append("\n### è¶‹åŠ¿åˆ†æ")
            trend = self._analyze_price_trend(kline_data)
            analysis_parts.append(f"- ä»·æ ¼è¶‹åŠ¿: {trend}")
            
            volume_trend = self._analyze_volume_trend(kline_data)
            analysis_parts.append(f"- æˆäº¤é‡è¶‹åŠ¿: {volume_trend}")
        
        # æŠ•èµ„å»ºè®®
        analysis_parts.append("\n### æŠ•èµ„å»ºè®®")
        if latest_quote and latest_quote.change_percent > 0:
            analysis_parts.append("- çŸ­æœŸ: è°¨æ…ä¹è§‚ï¼Œæ³¨æ„é£é™©æ§åˆ¶")
            analysis_parts.append("- ä¸­æœŸ: å…³æ³¨åŸºæœ¬é¢å˜åŒ–")
        else:
            analysis_parts.append("- çŸ­æœŸ: è§‚æœ›ä¸ºä¸»ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·")
            analysis_parts.append("- ä¸­æœŸ: å¯é€‚å½“å…³æ³¨ï¼Œåˆ†æ‰¹å»ºä»“")
        
        # é£é™©æç¤º
        analysis_parts.append("\n### é£é™©æç¤º")
        analysis_parts.append("- æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
        analysis_parts.append("- è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…")
        analysis_parts.append("- è¯·æ ¹æ®è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›åšå‡ºæŠ•èµ„å†³ç­–")
        
        return "\n".join(analysis_parts)
    
    def _analyze_price_trend(self, kline_data: List[KlineData]) -> str:
        """åˆ†æä»·æ ¼è¶‹åŠ¿"""
        if not kline_data or len(kline_data) < 2:
            return "æ•°æ®ä¸è¶³"
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_data = sorted(kline_data, key=lambda x: x.timestamp)
        
        # è®¡ç®—ä»·æ ¼å˜åŒ–
        start_price = float(sorted_data[0].close_price)
        end_price = float(sorted_data[-1].close_price)
        change_percent = (end_price - start_price) / start_price * 100
        
        if change_percent > 10:
            return "å¼ºåŠ¿ä¸Šæ¶¨"
        elif change_percent > 5:
            return "æ¸©å’Œä¸Šæ¶¨"
        elif change_percent > -5:
            return "éœ‡è¡æ•´ç†"
        elif change_percent > -10:
            return "æ¸©å’Œä¸‹è·Œ"
        else:
            return "å¤§å¹…ä¸‹è·Œ"
    
    def _analyze_volume_trend(self, kline_data: List[KlineData]) -> str:
        """åˆ†ææˆäº¤é‡è¶‹åŠ¿"""
        if not kline_data or len(kline_data) < 5:
            return "æ•°æ®ä¸è¶³"
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_data = sorted(kline_data, key=lambda x: x.timestamp)
        
        # è®¡ç®—å¹³å‡æˆäº¤é‡
        recent_volume = sum(item.volume for item in sorted_data[-5:]) / 5
        earlier_volume = sum(item.volume for item in sorted_data[-10:-5]) / 5 if len(sorted_data) >= 10 else recent_volume
        
        if recent_volume > earlier_volume * 1.5:
            return "æ”¾é‡"
        elif recent_volume < earlier_volume * 0.7:
            return "ç¼©é‡"
        else:
            return "å¹³ç¨³"
    
    async def get_market_insights(self, db: Session) -> Dict[str, Any]:
        """è·å–å¸‚åœºæ´å¯Ÿ"""
        try:
            # è·å–å¸‚åœºç»Ÿè®¡æ•°æ®
            market_stats = stock_service.get_market_summary(db)
            
            # ç”Ÿæˆå¸‚åœºæ´å¯Ÿ
            insights_prompt = "è¯·åŸºäºå½“å‰å¸‚åœºæ•°æ®æä¾›å¸‚åœºæ´å¯Ÿå’ŒæŠ•èµ„å»ºè®®"
            
            if self.chain and LANGCHAIN_AVAILABLE:
                insights = await self._generate_langchain_response(0, insights_prompt, {"market_data": market_stats})
            else:
                insights = await self._generate_market_insights_mock(market_stats)
            
            return {
                "insights": insights,
                "market_stats": market_stats,
                "timestamp": datetime.utcnow()
            }
            
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæ´å¯Ÿå¤±è´¥: {e}")
            return {"error": f"è·å–å¤±è´¥: {str(e)}"}
    
    async def _generate_market_insights_mock(self, market_stats: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå¸‚åœºæ´å¯Ÿ"""
        insights = []
        
        insights.append("## å¸‚åœºæ´å¯ŸæŠ¥å‘Š")
        insights.append(f"**æŠ¥å‘Šæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        
        if market_stats:
            total_stocks = market_stats.get("total_stocks", 0)
            insights.append(f"\n### å¸‚åœºæ¦‚å†µ")
            insights.append(f"- æ€»è‚¡ç¥¨æ•°é‡: {total_stocks}")
            
            market_dist = market_stats.get("market_distribution", {})
            for market, count in market_dist.items():
                insights.append(f"- {market}å¸‚åœº: {count}åªè‚¡ç¥¨")
        
        insights.append("\n### æŠ•èµ„ç­–ç•¥å»ºè®®")
        insights.append("1. **åˆ†æ•£æŠ•èµ„**: ä¸è¦å°†èµ„é‡‘é›†ä¸­åœ¨å•ä¸€è‚¡ç¥¨æˆ–è¡Œä¸š")
        insights.append("2. **ä»·å€¼æŠ•èµ„**: å…³æ³¨åŸºæœ¬é¢è‰¯å¥½çš„ä¼˜è´¨å…¬å¸")
        insights.append("3. **é£é™©æ§åˆ¶**: è®¾ç½®åˆç†çš„æ­¢æŸç‚¹")
        insights.append("4. **é•¿æœŸæŒæœ‰**: é¿å…é¢‘ç¹äº¤æ˜“")
        
        insights.append("\n### å¸‚åœºé£é™©æç¤º")
        insights.append("- å½“å‰å¸‚åœºæ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®è°¨æ…æ“ä½œ")
        insights.append("- å…³æ³¨å®è§‚ç»æµæ”¿ç­–å˜åŒ–")
        insights.append("- æ³¨æ„å›½é™…å¸‚åœºå½±å“")
        
        return "\n".join(insights)
    
    def get_conversation_history(self, user_id: int, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        if user_id not in self.conversation_history:
            return []
        
        history = self.conversation_history[user_id]
        return history[-limit:] if limit > 0 else history
    
    def clear_conversation_history(self, user_id: int) -> bool:
        """æ¸…ç©ºå¯¹è¯å†å²"""
        try:
            if user_id in self.conversation_history:
                self.conversation_history[user_id] = []
            
            # é‡ç½®LangChainå†…å­˜
            if self.memory:
                self.memory.clear()
            
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç©ºå¯¹è¯å†å²å¤±è´¥: {e}")
            return False
    
    async def get_smart_suggestions(self, db: Session, user_id: int, 
                                  suggestion_type: str = "general") -> List[Dict[str, Any]]:
        """è·å–æ™ºèƒ½å»ºè®®"""
        try:
            suggestions = []
            
            if suggestion_type == "watchlist":
                # åŸºäºç”¨æˆ·è‡ªé€‰è‚¡çš„å»ºè®®
                suggestions = await self._get_watchlist_suggestions(db, user_id)
            elif suggestion_type == "market":
                # å¸‚åœºæœºä¼šå»ºè®®
                suggestions = await self._get_market_suggestions(db)
            else:
                # é€šç”¨å»ºè®®
                suggestions = await self._get_general_suggestions()
            
            return suggestions
            
        except Exception as e:
            logger.error(f"è·å–æ™ºèƒ½å»ºè®®å¤±è´¥: {e}")
            return []
    
    async def _get_watchlist_suggestions(self, db: Session, user_id: int) -> List[Dict[str, Any]]:
        """è·å–è‡ªé€‰è‚¡ç›¸å…³å»ºè®®"""
        # è¿™é‡Œåº”è¯¥åŸºäºç”¨æˆ·çš„è‡ªé€‰è‚¡è¿›è¡Œåˆ†æ
        return [
            {
                "type": "watchlist",
                "title": "å…³æ³¨è‡ªé€‰è‚¡åŠ¨æ€",
                "content": "å»ºè®®å®šæœŸæ£€æŸ¥è‡ªé€‰è‚¡çš„åŸºæœ¬é¢å˜åŒ–å’ŒæŠ€æœ¯æŒ‡æ ‡",
                "priority": "medium",
                "timestamp": datetime.utcnow()
            }
        ]
    
    async def _get_market_suggestions(self, db: Session) -> List[Dict[str, Any]]:
        """è·å–å¸‚åœºæœºä¼šå»ºè®®"""
        return [
            {
                "type": "market",
                "title": "å…³æ³¨è¡Œä¸šè½®åŠ¨",
                "content": "å½“å‰ç§‘æŠ€æ¿å—è¡¨ç°æ´»è·ƒï¼Œå»ºè®®å…³æ³¨ç›¸å…³ä¼˜è´¨æ ‡çš„",
                "priority": "high",
                "timestamp": datetime.utcnow()
            }
        ]
    
    async def _get_general_suggestions(self) -> List[Dict[str, Any]]:
        """è·å–é€šç”¨å»ºè®®"""
        return [
            {
                "type": "general",
                "title": "é£é™©ç®¡ç†",
                "content": "å»ºè®®è®¾ç½®åˆç†çš„æ­¢æŸç‚¹ï¼Œæ§åˆ¶å•ç¬”æŠ•èµ„é‡‘é¢",
                "priority": "high",
                "timestamp": datetime.utcnow()
            },
            {
                "type": "general",
                "title": "å­¦ä¹ æå‡",
                "content": "å»ºè®®å®šæœŸå­¦ä¹ æŠ•èµ„çŸ¥è¯†ï¼Œæå‡åˆ†æèƒ½åŠ›",
                "priority": "medium",
                "timestamp": datetime.utcnow()
            }
        ]

# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
ai_service = AIAssistantService()